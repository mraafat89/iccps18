% P(:,:,1) = [0.1 0.9 0; ...
% 0.1 0 0.9; ...
% 0.1 0 0.9]; ...
% P(:,:,2) = [1 0 0; 1 0 0; 1 0 0];
% R(:,1) = [0 0 4]';
% R(:,2) = [0 1 2]';
clear all
close all
clc
%     _ _
%   B|_|_|     Actions: N=1, S=2, W=3, E=4
%   A|_|_|
%     1 2
%
%

%           A1  B1  A2  B2
P(:,:,1) = [0.1 0.8 0.1 0; ...
            0 0.9 0 0.1; ...
            0.1 0 0.1 0.8; ...
            0 0.1 0 0.9];
P(:,:,2) = [0.9 0 0.1 0; ...
            0.8 0.1 0 0.1; ...
            0.1 0 0.9 0; ...
            0 0.1 0.8 0.1];
P(:,:,3) = [0.9 0.1 0 0; ...
            0.1 0.9 0 0; ...
            0.8 0 0.1 0.1; ...
            0 0.8 0.1 0.1];
P(:,:,4) = [0.1 0.1 0.8 0; ...
            0.1 0.1 0 0.8; ...
            0 0 0.9 0.1; ...
            0 0 0.1 0.9];
        
R(:,1) = [-3 -3 -10000 100]';
R(:,2) = R(:,1);
R(:,3) = R(:,1);
R(:,4) = R(:,1);

% R(:,1) = [-3 -3 -100 100]';
% R(:,2) = [-3 -3 -100 100]';
% R(:,3) = [-3 -3 -100 100]';
% R(:,4) = [-3 -3 -100 100]';

% R(:,1) = [-200 -200 -100 100]';
% R(:,2) = [-200 -200 -100 100]';
% R(:,3) = [-200 -200 -100 100]';
% R(:,4) = [-200 -200 -100 100]';

discount = 0.9 %0.01999999
[V, policy] = mdp_policy_iteration(P, R, discount)

% Vpolicy = mdp_eval_policy_matrix (P, R, discount, policy)


%% POMDP
% 2 SENSORS TELL ME THAT I'M IN B1 P2= 2/3 
% 1 SENSOR TELLS ME THAT I'M IN A1 P1= 1/3

P1=1/3;
P2=2/3;

%           A1       B1               A2       B2
P(:,:,1) = [P1*0.1  P1*0.8+P2*0.9  P1*0.1  P2*0.1; ...
            P1*0.1  P1*0.8+P2*0.9  P1*0.1  P2*0.1; ...
            0.1 0 0.1 0.8; ...
            0 0.1 0 0.9];
P(:,:,2) = [P1*0.9+P2*0.8  P2*0.1  P1*0.1  P2*0.1; ...
            P1*0.9+P2*0.8  P2*0.1  P1*0.1  P2*0.1; ...
            0.1 0 0.9 0; ...
            0 0.1 0.8 0.1];
P(:,:,3) = [P1*0.9+P2*0.1  P1*0.1+P2*0.9  0  0; ...
            P1*0.9+P2*0.1  P1*0.1+P2*0.9  0  0; ...
            0.8 0 0.1 0.1; ...
            0 0.8 0.1 0.1];
P(:,:,4) = [P1*0.1+P2*0.1  P1*0.1+P2*0.1  P1*0.8  P2*0.8; ...
            P1*0.1+P2*0.1  P1*0.1+P2*0.1  P1*0.8  P2*0.8; ...
            0 0 0.9 0.1; ...
            0 0 0.1 0.9];

R(:,1) = [-3 -3 -10000 100]';
R(:,2) = R(:,1);
R(:,3) = R(:,1);
R(:,4) = R(:,1);


discount = 0.9 %0.01999999
[V, policy] = mdp_policy_iteration(P, R, discount)
        
        
